[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Análise de dados de Metagenômica",
    "section": "",
    "text": "Processamento e Análise de Dados de Metagenoma\nNeste repositório está o material para o curso Análise de dados de Metagenômica, organizado pelo Prof. Rodrigo Dalmolin, do Centro Multiusuário de Bioinformática da UFRN.\nO curso é dividido em 5 módulos:\n\nControle de qualidade e pré-processamento\nMontagem\nClassificação taxonômica\nAnotação funcional\nAnálises downstream:\n\nCálculos de diversidade e visualizações\nVisualizações da anotação funcional",
    "crumbs": [
      "Processamento e Análise de Dados de Metagenoma"
    ]
  },
  {
    "objectID": "content/01_setup.html",
    "href": "content/01_setup.html",
    "title": "1  Organizando Ambiente para Análise",
    "section": "",
    "text": "Primeiro, é necessário criar e ativar um ambiente Conda que contenha todas as ferramentas necessárias para os próximos passos. Caso ainda não tenha o Conda instalado, siga as instruções neste link.\n$ conda env create -f medusaPipeline.yml\n$ conda activate medusaPipeline\nA estrutura de diretórios a seguir ajudará na organização dos arquivos baixados, arquivos intermediários e seus outputs:\n$ mkdir -p ./Pipeline/{result,data/{merged,assembled,collapsed,removal/{index,reference},raw,trimmed},alignment/{db,index},taxonomic/db,functional/db}",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Organizando Ambiente para Análise</span>"
    ]
  },
  {
    "objectID": "content/02_qc.html",
    "href": "content/02_qc.html",
    "title": "2  Controle de Qualidade e Pré-processamento",
    "section": "",
    "text": "2.1 Baixar Amostras\nMude para o diretório Pipeline/data e baixe os arquivos de exemplo em pares (pair-end):",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Controle de Qualidade e Pré-processamento</span>"
    ]
  },
  {
    "objectID": "content/02_qc.html#baixar-amostras",
    "href": "content/02_qc.html#baixar-amostras",
    "title": "2  Controle de Qualidade e Pré-processamento",
    "section": "",
    "text": "$ cd Pipeline/data\n$ fasterq-dump SRR579292 -e 8\n\n\n\n\n\n\nNota\n\n\n\nO argumento -e no comando fasterq-dump especifica o número de threads que serão utilizadas. Adapte este argumento conforme o desempenho do seu sistema.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Controle de Qualidade e Pré-processamento</span>"
    ]
  },
  {
    "objectID": "content/02_qc.html#controle-de-qualidade-com-fastqc-e-multiqc",
    "href": "content/02_qc.html#controle-de-qualidade-com-fastqc-e-multiqc",
    "title": "2  Controle de Qualidade e Pré-processamento",
    "section": "2.2 Controle de Qualidade com FastQC e MultiQC",
    "text": "2.2 Controle de Qualidade com FastQC e MultiQC\n\n2.2.1 Estrutura de Arquivos .fastq\nO formato .fastq contém as sequências de DNA geradas no sequenciamento, junto com informações sobre a qualidade de cada nucleotídeo. A estrutura de um arquivo .fastq segue um padrão repetitivo a cada fragmento sequenciado:\n\nLinha 1: Contém o identificador único da leitura, que pode incluir informações sobre o sequenciador e a amostra (começa com o símbolo @).\nLinha 2: A sequência de nucleotídeos resultante do sequenciamento.\nLinha 3: Opcionalmente usada para anotações ou descrições adicionais (começa com um símbolo +).\nLinha 4: A qualidade de cada base na sequência, representada pelo Phred Score, que reflete a confiabilidade da leitura.\n\nA imagem abaixo exemplifica essa estrutura:\n\n\n\n\n\n\nEm Roxo: Identificador do sequenciamento.\nEm Laranja: Sequências adaptadoras (caso ainda não tenham sido removidas), que podem variar dependendo da plataforma de sequenciamento.\nEm Azul: O fragmento de DNA sequenciado, conhecido como “Insert Size”.\nEm Verde: Phred Score, que indica a qualidade de cada base na sequência.\n\n\n\n2.2.2 Ferramentas de Controle de Qualidade\nPara garantir que as sequências obtidas sejam de boa qualidade e adequadas para análise, utilizamos ferramentas como o FastQC e o MultiQC.\n\nFastQC: Avalia a qualidade de cada arquivo de sequenciamento individualmente, gerando relatórios com informações sobre a qualidade das bases, conteúdo GC, presença de adaptadores e outros aspectos que podem impactar a análise.\nMultiQC: Agrega os relatórios gerados pelo FastQC (ou outras ferramentas), criando um único relatório consolidado que facilita a visualização e interpretação dos dados de múltiplas amostras.\n\n\n\n2.2.3 Gerando Relatórios de Qualidade\nPara gerar relatórios de controle de qualidade com o FastQC para cada uma das amostras baixadas, use o seguinte comando:\n# Gerando relatórios de qualidade para cada amostra\nfor sample in $(ls Pipeline/data/*.fastq.gz); \ndo\nfastqc $sample -o Pipeline/data\ndone\nGere o relatório consolidado contendo todas as amostras a partir do output do FastQC:\n# Consolidando relatórios com MultiQC \n$ multiqc Pipeline/data\n\n\n\n\n\n\nInterpretando os resultados do MultiQC\n\n\n\nVerifique os gráficos de qualidade, presença de contaminantes e distribuições de qualidade das bases. Ajustes podem ser necessários para garantir a integridade dos dados para as etapas seguintes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Controle de Qualidade e Pré-processamento</span>"
    ]
  },
  {
    "objectID": "content/03_montagem.html",
    "href": "content/03_montagem.html",
    "title": "3  Montagem",
    "section": "",
    "text": "3.1 Contexto\nAs reads, ou leituras, fragmentos de sequências gerados pelo processo de sequenciamento, podem ser re-organizadas e mescladas em sequências mais longas e contíguas, ou contigs. Esse processo é denominado de Montagem.\nPara se realizar montagem, você pode utilizar uma referência, como o genoma referência de um organismo, que servirá como base para organizar as contigs. No entanto, no contexto metagenômico, a modalidade de montagem geralmente realizada é a montagem livre de referência, ou montagem de novo.\nComo montador de novo, utilizaremos o MEGAHIT.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Montagem</span>"
    ]
  },
  {
    "objectID": "content/03_montagem.html#realizando-a-montagem",
    "href": "content/03_montagem.html#realizando-a-montagem",
    "title": "3  Montagem",
    "section": "3.2 Realizando a montagem",
    "text": "3.2 Realizando a montagem\nVamos montar as leituras pós-descontaminação usando o MEGAHIT:\nmegahit -1 ../removal/unaligned_1.fastq -2\n../removal/unaligned_2.fastq -o SRR579292 -t 8 \nO arquivo de saída SRR579292.contigs.fa contém as sequências contíguas correspondentes às leituras usadas.\n\n\n\n\n\n\nNota\n\n\n\nOs passos seguintes, como a classificação taxonômica, podem se utilizar tanto das leituras quanto dos contigs. Iremos utilizar as leituras por motivos de didática, mas a maioria das ferramentas utilizadas para a análise de metagenômica podem fazer uso tanto de reads quanto de contigs.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Montagem</span>"
    ]
  },
  {
    "objectID": "content/04_taxonomia.html",
    "href": "content/04_taxonomia.html",
    "title": "4  Classificação Taxonômica",
    "section": "",
    "text": "4.1 Contexto",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Classificação Taxonômica</span>"
    ]
  },
  {
    "objectID": "content/04_taxonomia.html#realizando-a-classificação-taxonômica",
    "href": "content/04_taxonomia.html#realizando-a-classificação-taxonômica",
    "title": "4  Classificação Taxonômica",
    "section": "4.2 Realizando a classificação taxonômica",
    "text": "4.2 Realizando a classificação taxonômica\nMude o diretório atual para “Pipeline/taxonomic/db” e baixe os seguintes arquivos:\n$ wget ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/taxdump.tar.gz\n$ wget ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/accession2taxid/prot.accession2taxid.gz\nEsses são os bancos de dados que utilizaremos para executar o Kaiju\nExtraia e descompacte os arquivos necessários:\n$ tar -xf taxdump.tar.gz nodes.dmp names.dmp\n$ pigz -d prot.accession2taxid.gz -p 8\nConstrua um índice Kaiju:\n$ kaiju-convertNR -t nodes.dmp -g prot.accession2taxid -e ~/miniconda3/envs/medusaPipeline/bin/kaiju-excluded-accessions.txt -a -o kaijuNR.fasta -i ../../alignment/db/nr\n$ kaiju-mkbwt -n 8 -a ACDEFGHIKLMNPQRSTVWY -o kaijuNR kaijuNR.fasta\n$ kaiju-mkfmi kaijuNR\nNota: Na chamada kaiju-convertNR, por padrão, são incluídas apenas sequências de Archaea, Bactérias e Vírus do NCBI-nr. Este comportamento pode ser alterado com o argumento -l, passando um arquivo de entrada como ~/miniconda3/envs/medusaPipeline/bin/kaiju-taxonlistEuk.tsv. Este argumento utiliza apenas sequências com ancestrais listados no arquivo.\nMude o diretório atual para “Pipeline/taxonomic” e execute a classificação taxonômica:\n$ kaiju -t db/nodes.dmp -f db/kaijuNR.fmi -i ../data/removal/unaligned_1.fastq -j ../data/removal/unaligned_2.fastq -o ../result/SRR579292_kaiju.out -z 8\nAdicione os nomes dos táxons ao output:\n$ kaiju-addTaxonNames -t db/nodes.dmp -n db/names.dmp -r superkingdom,phylum,class,order,family,genus,species -i ../result/SRR579292_kaiju.out -o ../result/SRR579292_kaiju.names\nGere os gráficos Krona:\n$ kaiju2krona -t db/nodes.dmp -n db/names.dmp -i ../result/SRR579292_kaiju.out -o ../result/SRR579292_kaiju2krona.out\n$ ktImportText -o ../result/SRR579292_krona.html ../result/SRR579292_kaiju2krona.out",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Classificação Taxonômica</span>"
    ]
  },
  {
    "objectID": "content/05_anotacao.html",
    "href": "content/05_anotacao.html",
    "title": "5  Anotação Funcional",
    "section": "",
    "text": "5.1 annotate\nPara nosso primeiro exemplo, vamos utilizar a ferramenta annotate, que irá transferir identificadores de um resultado de alinhamento para identificadores funcionais, nesse caso termos do gene ontology.\nMas, para fazer isso, primeiro precisamos alinhar nosso dado a uma referência!",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Anotação Funcional</span>"
    ]
  },
  {
    "objectID": "content/05_anotacao.html#annotate",
    "href": "content/05_anotacao.html#annotate",
    "title": "5  Anotação Funcional",
    "section": "",
    "text": "5.1.1 Alinhamento\nESCREVER\n\n\n5.1.2 Executando o annotate\n\nVamos primeiro filtrar as colunas do nosso arquivo de referência para as que contém identificadores do GenBank e do Gene Ontology:\n\nawk -F \"\\\\t\" '{if((\\$7!=\"\") && (\\$18!=\"\")){print \\$18\"\\\\t\"\\$7}}' idmapping_selected.tab &gt; genbank2GO.txt\n\nE fazer o mesmo para termos um arquivo que traduz identificadores RefSeq para Gene Ontology:\n\nawk -F \"\\\\t\" '{if((\\$4!=\"\") && (\\$7!=\"\")){print \\$4\"\\\\t\"\\$7}}' idmapping_selected.tab &gt; refseq2GO.txt\n\nPodemos então executar um script R que irá limpar os dois arquivos, preparando-os para o formato do annotate:\n\n\n\n\n\n\n\nAviso\n\n\n\nO script requer bastante memória para lidar com o arquivo de mapeamento do UniProt, podendo requerir até 80GB de memória RAM para um dicionário típico.\n\n\ncreateDictionary.R \\\n        NR2GO.txt \\\n        genbank2GO.txt \\\n        refseq2GO.txt \\\n        4\n\nEm sequência, criamos o banco de dados do annotate:\n\nannotate createdb NR2GO.txt NR2GO 0 1 -d db\n\nE executamos o annotate para anotar cada query do alinhamento para seu identificador funcional:\n\nannotate idmapping ../alignment/all_matches.m8 ../result/SRR579292_functional_GO.txt NR2GO -l 1 -d db\n\n\n\n\n\n\nNota\n\n\n\nO argumento -l determina qual o comprimento mínimo de um alinhamento para ele ser considerado.\n\n\n\nAo explorar o arquivo de resultado do annotate podemos ver que ele possui o seguinte formato:\n\nQuery   Annotation\n342-2   GO:0005829; GO:0008720; GO:0047964; GO:0030267; GO:0016618; GO:0051287\n1560-1  GO:0005829; GO:0005886; GO:0003854; GO:0102294; GO:0070403; GO:0016616; GO:0004769; GO:0030283; GO:0016042; GO:0006694; GO:0008202\n3588-1  GO:0000775; GO:0005737; GO:0005829; GO:0090443; GO:0110085; GO:0044732; GO:0005634; GO:0000159; GO:0019888; GO:0061509; GO:0030952; GO:1990813; GO:0031030; GO:0006470\n5204-1  GO:0016491; GO:0008202\n7527-1  Unknown\n9319-1  GO:0042802; GO:0030170; GO:0008483; GO:0006520; GO:0009058\n9922-1  GO:0000775; GO:0005737; GO:0005829; GO:0090443; GO:0110085; GO:0044732; GO:0005634; GO:0000159; GO:0019888; GO:0061509; GO:0030952; GO:1990813; GO:0031030; GO:0006470\n10306-1 Unknown\n12743-1 GO:0005524; GO:0140658; GO:0004386; GO:0016787\nPara cada busca (“Query”) do seu alinhamento original, temos uma ou mais anotações em termos do Gene Ontology (“Annotation”)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Anotação Funcional</span>"
    ]
  },
  {
    "objectID": "content/06_analise_downstream.html",
    "href": "content/06_analise_downstream.html",
    "title": "6  Análises Downstream",
    "section": "",
    "text": "6.1 Cálculos de Diversidade",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análises Downstream</span>"
    ]
  },
  {
    "objectID": "content/06_analise_downstream.html#extraindo-informação-funcional",
    "href": "content/06_analise_downstream.html#extraindo-informação-funcional",
    "title": "6  Análises Downstream",
    "section": "6.2 Extraindo informação funcional",
    "text": "6.2 Extraindo informação funcional",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Análises Downstream</span>"
    ]
  },
  {
    "objectID": "content/05_anotacao.html#eggnog-mapper",
    "href": "content/05_anotacao.html#eggnog-mapper",
    "title": "5  Anotação Funcional",
    "section": "5.2 eggNOG-mapper",
    "text": "5.2 eggNOG-mapper\nO eggNOG-mapper é uma ferramenta que realiza anotação funcional de sequências contíguas. Ele usa informação de ortologia e filogenia para transferir identificadores funcionais às sequências. O eggNOG-mapper pode ser executado através de uma interface web mas aqui ilustraremos seu uso na linha de comando.\nPara isso, vamos utilizar as sequências contíguas que montamos anteriormente, na Seção 3.\n\nO eggNOG-mapper pode ser executado da seguinte maneira:\n\nemapper.py \\\n        -m diamond \\\n        --itype metagenome \\\n        -i SRR579292.contigs.fa \\\n        -o eggnog_results/SRR579292 \\\n        --cpu 6\nAs opções que utilizamos foram:\n\n-m: Sinaliza o “modo” de execução do eggnog, neste caso a ferramenta que será utilizada para realizar a busca por sequências. No nosso caso utilizamos o DIAMOND, ferramenta que já conhecemos na Sessão 5.1.1.\n--itype: Sinaliza o tipo de entrada (input) que damos a ferramenta, no nosso caso sequência contíguas originadas de um metagenoma.\n-i: Determina a entrada para a ferramenta.\n-o: Determina para onde deve ser escrita a saída da ferramenta.\n--cpu: O número de núcleos de processamento a serem utilizados pela ferramenta.\nUma vez que executamos o eggNOG-mapper, teremos um resultado no seguinte formato (eggnog_results/SRR579292.emapper.annotations):\n\n#query  seed_ortholog   evalue  score   eggNOG_OGs      max_annot_lvl   COG_category    Description     Preferred_name  GOs     EC      KEGG_ko KEGG_Pathway    KEGG_Module     KEGG_Reaction   KEGG_rclass     BRITE      KEGG_TC CAZy    BiGG_Reaction   PFAMs\nk141_94572      552396.HMPREF0863_01053 4.43e-45        159.0   COG0595@1|root,COG0595@2|Bacteria,1TQ9G@1239|Firmicutes,3VP2V@526524|Erysipelotrichia   526524|Erysipelotrichia S       Psort location Cytoplasmic, score  -       -       -       ko:K12574       ko03018,map03018        -       -       -       ko00000,ko00001,ko01000,ko03019 -       -       -       Lactamase_B,Lactamase_B_2,RMMBL\nk141_47286      1236514.BAKL01000034_gene2896   3.35e-79        254.0   COG5009@1|root,COG5009@2|Bacteria,4NECJ@976|Bacteroidetes,2FNAU@200643|Bacteroidia,4AKYH@815|Bacteroidaceae     976|Bacteroidetes       M COG5009 Membrane carboxypeptidase penicillin-binding protein     mrcA    -       2.4.1.129,3.4.16.4      ko:K05366       ko00550,ko01100,ko01501,map00550,map01100,map01501      -       -       -       ko00000,ko00001,ko01000,ko01003,ko01011    -       GT51    -       Transgly,Transpeptidase\nk141_141858     158189.SpiBuddy_1606    8.08e-76        239.0   COG1593@1|root,COG1593@2|Bacteria,2J6XN@203691|Spirochaetes     203691|Spirochaetes     G       transporter, DctM subunit       -       -       - --       -       -       -       -       -       -       -       DctM\nk141_23643      272563.CD630_25090      3.3e-45 159.0   COG1486@1|root,COG1486@2|Bacteria,1TQ9I@1239|Firmicutes,24995@186801|Clostridia 186801|Clostridia       G       family 4        -       -       3.2.1.122,3.2.1.86 ko:K01222,ko:K01232     ko00010,ko00500,map00010,map00500       -       R00837,R00838,R00839,R05133,R05134,R06113       RC00049,RC00171,RC00714 ko00000,ko00001,ko01000 -       GH4,GT4 -       Glyco_hydro_4,Glyco_hydro_4C\nk141_70929      1122985.HMPREF1991_02897        3.54e-11        65.5    COG1595@1|root,COG1595@2|Bacteria,4NS12@976|Bacteroidetes,2FQ76@200643|Bacteroidia      976|Bacteroidetes       K       RNA polymerase sigma-70 factor     -       -       -       ko:K03088       -       -       -       -       ko00000,ko03021 -       -       -       Sigma70_r2,Sigma70_r4_2\nBastante informação! Mas essencialmente semelhante à ferramenta anterior: Temos em cada linha uma sequência de busca advinda do nosso arquivo de montagem, e em cada uma das outras colunas, anotações para diferentes bancos de dados de informação funcional, além de colunas detalhando a qualidade de alinhamnto das nossas sequências à esses identificadores.\nPara mais informações sobre o arquivo de saída do eggNOG-mapper, confira a documentação da ferramenta.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Anotação Funcional</span>"
    ]
  }
]